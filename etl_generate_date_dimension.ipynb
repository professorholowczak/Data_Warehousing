{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/professorholowczak/Data_Warehousing/blob/main/etl_generate_date_dimension.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ETL Code Example for the Date Dimension in NYC 311 Data\n",
        "\n",
        "This example code creates a date dimension table in Google BigQuery.\n"
      ],
      "metadata": {
        "id": "L4nA8OxnlSfY"
      },
      "id": "L4nA8OxnlSfY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfa00868",
      "metadata": {
        "id": "cfa00868"
      },
      "outputs": [],
      "source": [
        "# Date Dimension\n",
        "# If using the native Google BigQuery API module:\n",
        "from google.cloud import bigquery\n",
        "from google.cloud.exceptions import NotFound\n",
        "import pandas as pd\n",
        "import os\n",
        "import pyarrow\n",
        "import logging\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If using a service account key file, save the path to that file in credentials.py and import credentials\n",
        "import credentials\n",
        "\n",
        "# If using Google CoLab, uncomment the following lines and Authenticate using CoLab\n",
        "# from google.colab import auth\n",
        "# auth.authenticate_user()\n",
        "# print('Authenticated')\n",
        "# Google Colab load modules for BigQuery\n",
        "# %load_ext google.cloud.bigquery\n",
        "# %load_ext google.colab.data_table"
      ],
      "metadata": {
        "id": "aC2HcbDkghE1"
      },
      "id": "aC2HcbDkghE1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46960187",
      "metadata": {
        "id": "46960187"
      },
      "outputs": [],
      "source": [
        "# Set the name of the dimension\n",
        "dimension_name = 'date'\n",
        "\n",
        "# Set the name of the surrogate key\n",
        "surrogate_key = dimension_name+'_dim_id'\n",
        "\n",
        "# Set the name of the business key\n",
        "business_key = dimension_name+'_id'\n",
        "\n",
        "# Set the GCP Project, dataset and table name\n",
        "gcp_project = 'put your GCP project name here'\n",
        "bq_dataset = 'nyc_311_complaints_dw'\n",
        "table_name = dimension_name+'_dimension'\n",
        "# Construct the full BigQuery path to the table\n",
        "dimension_table_path = \".\".join([gcp_project,bq_dataset,table_name])\n",
        "\n",
        "# Set the path to the source data files. Use double-slash for Windows paths C:\\\\myfolder\n",
        "# For Linux use forward slashes    /home/username/python_etl\n",
        "# For Mac use forward slashes      /users/username/python_etl\n",
        "file_source_path = 'c:\\\\Python_ETL'\n",
        "file_source_path = 'C:\\\\Users\\\\rholo\\\\OneDrive\\\\Documents\\\\classes\\\\4400\\\\311'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "060f8796",
      "metadata": {
        "id": "060f8796"
      },
      "outputs": [],
      "source": [
        "# Set up logging\n",
        "current_date = datetime.today().strftime('%Y%m%d')\n",
        "log_filename = \"_\".join([\"etl\",dimension_name,current_date])+\".log\"\n",
        "logging.basicConfig(filename=log_filename, encoding='utf-8', format='%(asctime)s %(message)s', level=logging.DEBUG)\n",
        "logging.info(\"=========================================================================\")\n",
        "logging.info(\"Starting ETL Run for dimension \"+dimension_name+\" on date \"+current_date)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "436af56f",
      "metadata": {
        "id": "436af56f"
      },
      "outputs": [],
      "source": [
        "def generate_date_dimension(start='2016-01-01', end='2026-12-31'):\n",
        "    \"\"\"\n",
        "    generate_date_dimension\n",
        "    Creates a calendar of all dates between 'start' and 'end'\n",
        "    Then adds additional columns of day, week and month information in various formats\n",
        "    See this for format details: https://docs.python.org/3/library/datetime.html#strftime-and-strptime-format-codes\n",
        "    Returns a new dataframe\n",
        "    \"\"\"\n",
        "    df = pd.DataFrame({\"full_date\": pd.date_range(start, end)})\n",
        "    df[\"weekday_name\"] = df.full_date.dt.strftime(\"%A\")\n",
        "    df[\"day_of_week\"] = df.full_date.dt.strftime(\"%w\")\n",
        "    df[\"month_name\"] = df.full_date.dt.strftime(\"%B\")\n",
        "    df[\"day_of_month\"] = df.full_date.dt.strftime(\"%d\")\n",
        "    df[\"month_of_year\"] = df.full_date.dt.strftime(\"%m\")\n",
        "    df[\"quarter\"] = df.full_date.dt.quarter\n",
        "    df[\"year\"] = df.full_date.dt.strftime(\"%Y\")\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d1bee48",
      "metadata": {
        "id": "0d1bee48"
      },
      "outputs": [],
      "source": [
        "def create_bigquery_client(logging):\n",
        "    \"\"\"\n",
        "    create_bigquery_client\n",
        "    Creates a BigQuery client using the path to the service account key file\n",
        "    for credentials.\n",
        "    Returns the BigQuery client object\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # If using  a service account key file create the client this way:\n",
        "        bqclient = bigquery.Client.from_service_account_json(credentials.path_to_service_account_key_file)\n",
        "        # If using Google Colab authentication then create the client this way:\n",
        "        # bqclient = bigquery.Client(gcp_project)\n",
        "        logging.info(\"Created BigQuery Client: %s\",bqclient)\n",
        "        return bqclient\n",
        "    except Exception as err:\n",
        "        logging.error(\"Failed to create BigQuery Client.\", err)\n",
        "        os._exit(-1)\n",
        "    return bqclient\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3578f519",
      "metadata": {
        "id": "3578f519"
      },
      "outputs": [],
      "source": [
        "def upload_bigquery_table(logging, bqclient, table_path, write_disposition, df):\n",
        "    \"\"\"\n",
        "    upload_bigquery_table\n",
        "    Accepts a path to a BigQuery table, the write disposition and a dataframe\n",
        "    Loads the data into the BigQuery table from the dataframe.\n",
        "    for credentials.\n",
        "    The write disposition is either\n",
        "    write_disposition=\"WRITE_TRUNCATE\"  Erase the target data and load all new data.\n",
        "    write_disposition=\"WRITE_APPEND\"    Append to the existing table\n",
        "    \"\"\"\n",
        "    try:\n",
        "        logging.info(\"Creating BigQuery Job configuration with write_disposition=%s\", write_disposition)\n",
        "        # Set up a BigQuery job configuration with the write_disposition.\n",
        "        job_config = bigquery.LoadJobConfig(write_disposition=write_disposition)\n",
        "        # Submit the job\n",
        "        logging.info(\"Submitting the BigQuery job\")\n",
        "        job = bqclient.load_table_from_dataframe(df, table_path, job_config=job_config)\n",
        "        # Show the job results\n",
        "        logging.info(\"Job  results: %s\",job.result())\n",
        "    except Exception as err:\n",
        "        logging.error(\"Failed to load BigQuery Table. %s\", err)\n",
        "        #os._exit(-1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d37a312",
      "metadata": {
        "id": "3d37a312"
      },
      "outputs": [],
      "source": [
        "def bigquery_table_exists(bqclient, table_path):\n",
        "    \"\"\"\n",
        "    bigquery_table_exists\n",
        "    Accepts a path to a BigQuery table\n",
        "    Checks if the BigQuery table exists.\n",
        "    Returns True or False\n",
        "    \"\"\"\n",
        "    try:\n",
        "        bqclient.get_table(table_path)  # Make an API request.\n",
        "        return True\n",
        "    except NotFound:\n",
        "        return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79339f5c",
      "metadata": {
        "id": "79339f5c"
      },
      "outputs": [],
      "source": [
        "def query_bigquery_table(logging, table_path, bqclient, surrogate_key):\n",
        "    \"\"\"\n",
        "    query_bigquery_table\n",
        "    Accepts a path to a BigQuery table and the name of the surrogate key\n",
        "    Queries the BigQuery table but leaves out the update_timestamp and surrogate key columns\n",
        "    Returns the dataframe\n",
        "    \"\"\"\n",
        "    bq_df = pd.DataFrame\n",
        "    sql_query = 'SELECT * EXCEPT ( update_timestamp, '+surrogate_key+') FROM `' + table_path + '`'\n",
        "    logging.info(\"Running query: %s\", sql_query)\n",
        "    try:\n",
        "        bq_df = bqclient.query(sql_query).to_dataframe()\n",
        "    except Exception as err:\n",
        "        logging.info(\"Error querying the table. %s\", err)\n",
        "    return bq_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "484a7699",
      "metadata": {
        "id": "484a7699"
      },
      "outputs": [],
      "source": [
        "def add_surrogate_key(df, dimension_name='customers', offset=1):\n",
        "    \"\"\"\n",
        "    add_surrogate_key\n",
        "    Accepts a data frame and inserts an integer identifier as the first column\n",
        "    Returns the modified dataframe\n",
        "    \"\"\"\n",
        "    # Reset the index to count from 0\n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "    # Add the new surrogate key starting from offset\n",
        "    df.insert(0, dimension_name+'_dim_id', df.index+offset)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de2d5c71",
      "metadata": {
        "id": "de2d5c71"
      },
      "outputs": [],
      "source": [
        "def add_update_date(df, current_date):\n",
        "    \"\"\"\n",
        "    add_update_date\n",
        "    Accepts a data frame and inserts the current date as a new field\n",
        "    Returns the modified dataframe\n",
        "    \"\"\"\n",
        "    df['update_date'] = pd.to_datetime(current_date)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2125588",
      "metadata": {
        "id": "b2125588"
      },
      "outputs": [],
      "source": [
        "def add_update_timestamp(df):\n",
        "    \"\"\"\n",
        "    add_update_timestamp\n",
        "    Accepts a data frame and inserts the current datetime as a new field\n",
        "    Returns the modified dataframe\n",
        "    \"\"\"\n",
        "    df['update_timestamp'] = pd.to_datetime('now', utc=True).replace(microsecond=0)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b62db0af",
      "metadata": {
        "id": "b62db0af"
      },
      "outputs": [],
      "source": [
        "def build_new_table(logging, bqclient, dimension_table_path, dimension_name, df):\n",
        "    \"\"\"\n",
        "    build_new_table\n",
        "    Accepts a path to a dimensional table, the dimension name and a data frame\n",
        "    Add the surrogate key and a record timestamp to the data frame\n",
        "    Inserts the contents of the dataframe to the dimensional table.\n",
        "    \"\"\"\n",
        "    logging.info(\"Target dimension table %s does not exit\", dimension_table_path)\n",
        "    # Add a surrogate key\n",
        "    df = add_surrogate_key(df, dimension_name, 1)\n",
        "    # Add the update timestamp\n",
        "    df = add_update_timestamp(df)\n",
        "    # Upload the dataframe to the BigQuery table\n",
        "    upload_bigquery_table(logging, bqclient, dimension_table_path, \"WRITE_TRUNCATE\", df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c720d52",
      "metadata": {
        "id": "9c720d52"
      },
      "outputs": [],
      "source": [
        "def insert_existing_table(logging, bqclient, dimension_table_path, dimension_name, surrogate_key, df):\n",
        "    \"\"\"\n",
        "    insert_existing_table\n",
        "    Accepts a path to a dimensional table, the dimension name and a data frame\n",
        "    Compares the new data to the existing data in the table.\n",
        "    Inserts the new/modified records to the existing table\n",
        "    \"\"\"\n",
        "    bq_df = pd.DataFrame\n",
        "    logging.info(\"Target dimension table %s exits. Checking for differences.\", dimension_table_path)\n",
        "    # Fetch the existing table\n",
        "    bq_df = query_bigquery_table(logging, dimension_table_path, bqclient, surrogate_key)\n",
        "    # Compare with the new data set\n",
        "    new_records_df = pd.concat([df,bq_df]).drop_duplicates(keep=False)\n",
        "    logging.info(\"Found %d new records.\", new_records_df.shape[0])\n",
        "    if new_records_df.shape[0] > 0:\n",
        "        # Set the surrogate key for the new records. bq_df.shape[0] is number of records already in the database\n",
        "        new_surrogate_key_value = bq_df.shape[0]+1\n",
        "        new_records_df = add_surrogate_key(new_records_df, dimension_name, new_surrogate_key_value)\n",
        "        # Add the current date for the new records\n",
        "        new_records_df = add_update_timestamp(new_records_df)\n",
        "        # Upload the new records into the dimension table\n",
        "        upload_bigquery_table(logging, bqclient, dimension_table_path, \"WRITE_APPEND\", new_records_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55edebde",
      "metadata": {
        "scrolled": true,
        "id": "55edebde"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    df = pd.DataFrame\n",
        "    # Generate the date dimension - change the date range to match your data\n",
        "    df = generate_date_dimension(start='2016-01-01', end='2026-12-31')\n",
        "    # Create the BigQuery Client\n",
        "    bqclient = create_bigquery_client(logging)\n",
        "    # See if the target dimensional table exists\n",
        "    target_table_exists = bigquery_table_exists(bqclient, dimension_table_path  )\n",
        "    # If the target dimension table does not exist, load all of the data into a new table\n",
        "    if not target_table_exists:\n",
        "        build_new_table(logging, bqclient, dimension_table_path, dimension_name, df)\n",
        "    # If the target table exists, then perform an incremental load\n",
        "    if target_table_exists:\n",
        "        print(\"Date dimension already exists. Will not overwrite it\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}